                            Network Error Logging:
          Client-side measurement of end-to-end web service reliability
 Sam Burnett1 , Lily Chen1 , Douglas A. Creager3 , Misha Efimov1 , Ilya Grigorik1 , Ben Jones1 , Harsha V.
         Madhyastha1,2 , Pavlos Papageorge1 , Brian Rogan1 , Charles Stahl1 , and Julia Tuttle1
                                     1             2                                 3
                                         Google     University of Michigan               GitHub
                                                    nel-paper@google.com
                          Abstract                                    To address this challenge, a range of approaches have been
                                                                   developed over the years. For instance, server-side request
   We present NEL (Network Error Logging), a planet-scale,
                                                                   logs (e.g., the Apache web server’s access.log and error.log
client-side, network reliability measurement system. NEL
                                                                   files [31]) give fine-grained information about the success or
is implemented in Google Chrome and has been proposed
                                                                   failure of each incoming request. After annotating these logs
as a new W3C standard, letting any web site operator col-
                                                                   with additional information, like the ISP or geographic loca-
lect reports of clients’ successful and failed requests to their
                                                                   tion of the end user, operators can identify when interesting
sites. These reports are similar to web server logs, but
                                                                   populations of end users are all affected by the same reliabil-
include information about failed requests that never reach
                                                                   ity issues [5, 4]. Alternative approaches rely on a dedicated
serving infrastructure. Reports are uploaded via redundant
                                                                   monitoring infrastructure comprising a globally distributed
failover paths, reducing the likelihood of shared-fate failures
                                                                   set of vantage points. These approaches either actively probe
of report uploads. We have designed NEL such that service
                                                                   the service to detect unreachability [6, 20] or passively mon-
providers can glean no additional information about users or
                                                                   itor BGP feeds to identify routing issues [7].
their behavior compared to what services already have vis-
                                                                      Unfortunately, these existing solutions suffer from two
ibility into during normal operation. Since 2014, NEL has
                                                                   fundamental limitations.
been invaluable in monitoring all of Google’s domains, al-
lowing us to detect and investigate instances of DNS hijack-       • First, they are typically capable of only detecting large,
ing, BGP route leaks, protocol deployment bugs, and other            systemic outages. For example, with server-side moni-
problems where packets might never reach our servers. This           toring, a major problem (e.g., a global outage of a major
paper presents the design of NEL, case studies of real out-          service, or a regional outage affecting a large enough re-
ages, and deployment lessons for other operators who choose          gion) might show up as a noticeable drop in total request
to use NEL to monitor their traffic.                                 volume [28], but operators typically only learn of smaller
                                                                     problems when users manually report them.1 These user
1   Introduction                                                     reports are often frustratingly vague, and collecting addi-
Maintaining high availability is a matter of utmost impor-           tional information from nonexpert users is next to impos-
tance for the operator of any popular web service. When              sible, so investigation may take hours or even days.
users cannot access a web service, this may not only result in     • Second, and more importantly, existing approaches are in-
loss of revenue for the service provider but may also impact         capable of precisely quantifying how many clients are af-
the service’s reputation, causing users to shift to competing        fected, if any. For example, active probing from dedicated
services. Therefore, it is critical that a web service opera-        probing infrastructure can only probe from a handful of
tor detect and react in a timely manner when its service is          locations relative to the number of real users, and probe
inaccessible for any sizable population of users.                    traffic is not always representative of what actual users ex-
   The primary challenge in doing so is that network traffic         perience (e.g., probers may not use real web browsers and
faces many threats as it traverses the Internet from clients         might receive different network configuration than actual
to servers, most of which are outside the control of the ser-        end users). Without knowing how many users are affected,
vice operator. Rogue DNS resolvers can serve hijacked re-            the operator is unable to judge whether it should prioritize
sults [2], ISP middleboxes can surgically alter traffic [27],        the troubleshooting of a detected problem over other on-
bad router policy can silently drop packets [24], misconfig-         going issues that deserve its attention.
ured BGP can take entire organizations offline [1], and more.         To overcome these challenges in detecting and scoping in-
Even though each of these issues is caused by systems that         stances of service unreachability, we need a system that (1)
are not under the web service operator’s control, the operator
must bear primary responsibility for detecting and respond-            1 While sites like https://downdetector.com crowdsource such reports,

ing to them.                                                       historically we have often only learned of problems via social media.

passively monitors actual end user traffic to any target web
service; (2) has visibility into reliability issues regardless of
where on the end-to-end path they occur; and (3) requires lit-
tle to no custom engineering work on the part of the operator.
   With these goals in mind, we have designed, implemented,
and deployed NEL (Network Error Logging). The key intu-
ition behind NEL’s design is that clients have ground truth
about their ability to access a web service. Therefore, NEL
leverages end users’ browsers to collect reliability informa-
tion about the service. NEL is implemented directly in
                                                                    Figure 1: Steps and entities involved in enabling a client to ac-
the browser’s network stack, collecting metadata about the
                                                                    cess a web service.
outcome of requests, without requiring any custom per-site
JavaScript instrumentation. The browser then uploads these          only coarse-grained summaries about entire requests, and is
reports to a redundant set of collection servers, which aggre-      no substitute for lower-level network diagnostics like trace-
gates reports from users around the globe to detect and scope       routes and packet captures. (For example, it can detect when
network outages.                                                    clients experience connection timeouts, but cannot tell you
   This paper describes our contributions, based on the fol-        much more about why.) Nonetheless, NEL has proven a
lowing three tracks:                                                valuable tool for detecting and scoping network outages that
   First, we present our solutions to the various engineering       are invisible to other monitoring infrastructure.
and policy challenges that arise in using client-side data to
detect reachability issues. When clients are unable to talk
                                                                    2     Background and Motivation
to a service, how do we still ensure successful collection of       We begin by listing several causes that may render a web ser-
unreachability reports from these clients? What should up-          vice inaccessible, solutions that exist to detect service reach-
loaded reports contain so that they aid in diagnosing and es-       ability problems, and the limitations of these solutions that
timating the impact of outages? How do we prevent abuse of          motivated us to develop NEL.
the system, given that clients are free to upload fraudulent re-
                                                                    2.1    Causes of service inaccessibility
ports and service operators can attempt to learn about clients’
reachability to other services? Our primary consideration in        As Figure 1 shows, a typical communication between a client
answering these questions has been to preserve user privacy;        and a web service offered over HTTPS involves the follow-
we ensure that NEL does not reveal more about clients than          ing steps: the client performs a DNS lookup of the service’s
what service operators would learn during normal operation.         hostname, establishes a TCP connection to the IP address it
   Second, we describe our experiences in using NEL to              obtains, performs a TLS handshake with the server, and then
monitor reachability to Google’s services since 2014. In that       sends its HTTP request.2
time, as we relay in Section 4, it has been instrumental in           Given these steps, a client may be unable to communicate
detecting and mitigating a wide variety of network outages          with a web service due to any of the following reasons:
including routing loops, BGP leaks, DNS hijacks, and proto-         • DNS failure: The client will be unable to execute any
col misconfigurations. In particular, without NEL, it would           of the subsequent steps if its attempt to resolve the ser-
have been hard, if not impossible, to estimate the number of          vice’s hostname fails. This can happen either if the name-
clients affected by each outage. Thus, NEL has proved in-             server that the client uses is unresponsive, or if the service
valuable in helping us identify which problems warrant im-            provider’s DNS setup is misconfigured.
mediate investigation due to their large impact and which
ones we can afford to ignore or attend to later.                    • DNS hijack: The client could get an incorrect IP address
   Third, after several years of experience with an initial im-       in response to its DNS request if either the nameserver that
plementation that could only monitor Google services, we              the client uses is compromised or if the client is compro-
describe our recent efforts to promote this capability as a new       mised to use a malicious nameserver.
proposed W3C standard [11]. Standardizing this work has             • IP unreachability: When the client does get a correct IP
two benefits: (1) it allows all service operators to take advan-      address, the Internet may be unable to route packets from
tage of this new collection ability, and (2) it allows operators      the client to that IP, either due to problems with BGP (e.g.,
to collect reliability data from any user agent that complies         misconfiguration or convergence delays) or because of ac-
with the standard, and not just Chrome.                               tive blocking by network operators.
   NEL is not a panacea for painstaking problem detection               2 Note that this only considers the user’s communication with a “front-
and diagnosis. It cannot report problems when clients are           end” server. Modern services typically require many back-end service calls
completely disconnected from the network or cannot reach            to generate the final response, which are hidden behind the interaction with
at least one of a redundant set of collectors. It reports           the front-end server, and invisible to the client (and by extension, NEL).

• Prefix hijack: Alternatively, if the prefix which contains              Data source           Enable       Detect    Estimate #
  the IP address has been hijacked, the client’s requests                                       timely     localized   of affected
  will be directed to servers not controlled by the service                                    detection    outages      clients
  provider. The client will hence be (hopefully) unable to             Distributed moni-         X            ⇥            ⇥
  complete TLS connection setup.                                       toring infrastructure
• Faulty middlebox: When IP-level reachability between                 Service logs              X            ⇥            ⇥
  the client and the service is functional, the client’s attempt       Backscatter traffic        ⇥           ⇥            ⇥
  to connect to the service may still fail due to a misconfig-         User reports               ⇥          X             ⇥
  ured or malicious middlebox enroute.                                 NEL                       X           X            X
• Service faulty/down: Lastly, even if the client’s DNS            Table 1: Properties satisfied by different approaches for detect-
  lookup succeeds and both IP-level and TLS-level connec-          ing service reachability problems at scale.
  tivity are unhindered, the client will be unable to access a
  service that is down or misconfigured.                           dictability. As a result, drops in traffic volumes for small
                                                                   populations of users are not adequate evidence for service
2.2   Existing solutions and limitations                           operators to take action.
To detect unreachability caused by the above-mentioned             Monitoring backscatter traffic. Similar limitations ex-
problems, a wide range of solutions have been developed            ist with solutions that rely on backscatter traffic—traffic that
over the years. This body of prior work falls broadly into         clients send to unused portions of the IP address space—to
four categories.                                                   detect reachability issues [12]. Here too, one has to infer (for
                                                                   example) censorship based on the absence of traffic. Conse-
Monitoring from distributed vantage points. A popular
                                                                   quently, problems can be reliably detected only when they
approach is to monitor reachability from a dedicated set of
                                                                   are large in scope. Moreover, even when backscatter traffic
distributed vantage points. Solutions that use this approach
                                                                   shows an absence of traffic from a large population, those
either actively probe services from devices that mimic real
                                                                   users likely cannot reach any IP address.
clients [3, 6]—probing can either be at the application level
(e.g., in the form of HTTP requests) or at the routing level       Leveraging user reports. An approach which can detect
(e.g., in the form of traceroutes)—or passively monitor BGP        localized problems, unlike the previous categories of solu-
updates (e.g., to detect prefix hijacks [22, 19]), or use some     tions, is to rely on complaints/reports from users. However,
combination of the two [20, 35]. Such approaches can de-           such solutions are typically incapable of detecting reachabil-
tect problems that have wide impact. Localized problems            ity problems in a timely, reproduceable, representative, and
are, however, likely to go unnoticed because a set of vantage      consistent manner. For example, users in some regions may
points typically cannot match the global coverage of a ser-        be less likely to notify service operators about problems, due
vice’s clients. Moreover, when unreachability is detected, it      to language or cultural barriers.
is hard to estimate how many real clients are affected.               Table 1 summarizes the limitations of these existing solu-
                                                                   tions. The overriding one, which motivated our development
Monitoring service logs. To ensure broad coverage, ser-
                                                                   of NEL, is the inability to accurately estimate how many
vice providers can monitor their service’s usage either by an-
                                                                   clients are currently affected by an outage. In our experi-
alyzing server-side logs or by augmenting pages on their site
                                                                   ence, a high confidence estimate of the scope of a problem
with JavaScript that performs and uploads client-side mea-
                                                                   is the top criterion to warrant investigation by a service op-
surements (popularly referred to as Real User Monitoring, or
                                                                   erator. Lacking such data, it is hard to triage and prioritize
RUM for short [9]). With either strategy, operators must infer
                                                                   human effort to troubleshoot the large number of issues that
reachability problems from the absence of traffic. Requests
                                                                   a service provider has to deal with at any point in time.
from affected users will never arrive at the server and there-
fore are absent from server-side logs, whereas users unable        3     Design
to fetch even the HTML of a web page will not execute any
JavaScript included on the page, even if cached. For any pop-      This section presents the design of NEL, our browser-based
ulation of users, a significant drop in requests compared to       mechanism for collecting information about a web service’s
what is typically expected (given historical traffic volumes)      availability, as seen by its clients. By using the client as the
may indicate a reachability problem being experienced by           vantage point, the operator gains explicit information about
these users. The challenge here is: how to distinguish be-         the impact of reliability problems, rather then having to esti-
tween localized reachability problems and intrinsic volatility     mate the impact based on either the absence of traffic or by
in traffic volumes? While traffic in aggregate across a large      extrapolating from a small set of clients.
population of users is typically fairly predictable (e.g., same       Google has twice implemented the ideas behind NEL: first
from a particular hour in a week to that hour next week), the      as a proof of concept that could only monitor reachability to
smaller the subset of users considered, the larger the unpre-      Google properties, and again as a proposed public W3C stan-

                                                            1. Successful              3. End users can opt out of collection at any time, either
                                                            HTTP request
                            ctivation                                                     globally or on a per-site basis. Support for respecting opt-
                  2. NEL a nse header
                       P re po
                           s                                                              outs must be implemented by NEL-compliant user agents,
            via HTT                                                                       so that users do not need to trust service providers for opt-
                                  quest                     Web server
                 Fa iled  HTTP re                                                         outs to take effect.
             3 .
                                                                                       4. Modulo that end-user opt-out, it is only the site owner who
                                                         NEL collector                    gets to decide whether reports are collected about a par-
 Client           4. NEL re
                           p   ort                                                        ticular site, and if so, where they are sent. Third parties
                                                                                          (including browser vendors) must not be able to use NEL
Figure 2: When a client successfully communicates with a ser-                             to monitor sites that they do not control.
vice, collection of client-side reports is activated via a NEL pol-
icy in the service’s response headers. The client reportsConfidental
                                                            the suc- and proprietary
                                                                                          These principles have clear ramifications on the design of
cess and failure of its subsequent requests to that service to col-                    the system, as we discuss below in our description of NEL’s
lectors referenced in the NEL policy.                                                  design; Table 2 provides a summary.
dard [11] available to all service operators. Here, we focus                           3.3 When do clients generate reports?
on the latter due to its general availability. We also summa-
rize important differences between the two implementations.                            Configuration via response headers. How does a user
                                                                                       agent know which requests to collect reports about? An op-
3.1    Approach and challenges                                                         erator needs a way to instruct client browsers to collect re-
When stated at a high level, NEL’s approach is fairly sim-                             ports about requests to services they control, along with any
ple and intuitive: clients upload reports summarizing their                            configuration parameters about that collection.
ability to either successfully or unsuccessfully access target                            HTTP response headers provide exactly what we
services. In aggregate, such reports enable the provider to                            need: service operators insert policy configuration head-
piece together the ground truth as to how many, and which,                             ers (Report-To and NEL) into their outgoing responses; Fig-
of its clients are unable to access its service.                                       ure 3(a) shows an example. The user agent’s network stack
   Realizing this approach in practice requires us to answer                           intercepts these policy headers as part of the normal process-
several questions:                                                                     ing of the response. NEL is limited to secure connections—
• How do clients know which services to collect reliability                            HTTPS connections with validated certificates—ensuring
  information about?                                                                   that (in the absence of a subversion of the certificate trust
                                                                                       validation mechanism) third parties cannot inject NEL poli-
• What should clients include in reports they upload?                                  cies into the responses of servers not under their control.
• In order to reliably report that information, where should                              If an attacker does somehow subvert connection security,
  clients upload reports to?                                                           they could inject NEL’s HTTP headers and can obtain NEL
  Before describing our answers to these questions (sum-                               monitoring data. For example, a malicious or compromised
marized in an illustration of NEL’s architecture in Figure 2),                         CDN provider could siphon NEL logs off to their own col-
we first list the properties required of such a system, which                          lector. But such an attacker could obtain the same data by
motivate our design choices.                                                           other means (e.g., by injecting additional JavaScript).
3.2    Security, privacy, and ethics                                                   Scope of activation. We need to ensure that client-side
                                                                                       collection of NEL reports does not allow third parties to col-
When designing NEL, we have to balance collecting enough                               lect information about sites they do not control. The cleanest
information to enable quick detection of reliability issues                            way to do this is to follow the existing Same-Origin Policy
versus satisfying the security and privacy expectations of                             (SOP) [8], and to have report collection be scoped to the ori-
both service owners and their end users. There are four prin-                          gin (domain name, scheme, and port) of the request. That is,
ciples in particular that we must follow:                                              collection would be activated (or deactivated) for all requests
1. We cannot collect any information about end users, their                            to an origin; any collection policy configured for origin A
   device/user agent, or their network configuration, that the                         would have no effect on requests to origin B, even if both
   server does not already have visibility into. That is, we                           origins happen to be owned and operated by the same entity.
   should not collect new information relative to existing                                Note that NEL does not preclude user agents from gener-
   server logs; only existing information in a different place.                        ating NEL reports even when the user is in private browsing
2. We can only collect information about requests that user                            mode. In such cases, any service’s server-side logs do re-
   agents issue when users voluntarily access services on the                          flect the user’s use of its service. NEL is simply collecting
   Web. We cannot issue requests in the background (i.e.,                              the same information at the client and uploading it via re-
   outside of normal user activity), even though this prevents                         dundant paths to the same service provider. As we describe
   us from proactively ascertaining service reachability.                              later in this section, the contents of any NEL report ensure

            Goal                                    Approach                                        Refinements/Experience
                                                                                       • With include subdomains option, one success-
  Securely activate client-    • Include NEL policy header in HTTP responses
                                                                                         ful communication with an origin suffices for a
  side collection of reacha-   • Enforce Same-Origin Policy
                                                                                         user agent to start collecting (some) reports for
  bility reports               • Limit to HTTPS connections
                                                                                         all subdomains of that origin
  Ensure report content pre-   • Only include information that is visible to service   • Upload reports even for successful requests to
  serves user privacy, yet       during normal operation                                 establish baseline request rate and to reduce
  aids diagnosis               • Limited set of hierarchically organized error types     burstiness of collection workload
                               • Causes that can render collectors unreachable         • Specify weight and priority per collector to bal-
                                 should be disjoint from those that can affect the       ance load and to enable failover across collectors
  Enable secure and timely
                                 service’s reachability                                • Configurable sampling rates to reduce load on
  collection of NEL re-
                               • Client downgrades report (removing sensitive in-        both clients and collectors
  ports from clients
                                 formation) if service’s IP address is not one from    • Host collectors on cloud infrastructure to deter
                                 which it has received NEL policy for this origin        censorship of report collection

 Table 2: Summary of the approach taken in NEL to address different design decisions, along with experience-based refinements.

that the service provider can glean no additional information            cannot help an operator discover a client’s inability to access
about its users than it can from its server-side logs.                   their service unless the client has successfully communicated
                                                                         with the service at least once in the past. To minimize the
Preventing DNS rebinding attacks. On its own, SOP is
                                                                         impact of this constraint on service providers, a NEL pol-
not enough to prevent a malicious actor from using NEL to
                                                                         icy can include the include subdomains field, which tells the
learn about the reachability of origins that they do not con-
                                                                         user agent to collect and upload reports for both the origin as
trol. Consider a rebinding attack, where an attacker who
                                                                         well as all of its subdomains.
owns bad.example wishes to learn about the availability of
                                                                            At first glance, this is a clear violation of SOP: there is no
good.example. They start by configuring DNS to resolve
                                                                         guarantee that the web sites hosted at each subdomain are
bad.example to a server that they control (using a short TTL),
                                                                         owned by the same entity.3 To maintain our privacy proper-
and getting an end user to make a request to bad.example.
                                                                         ties, a user agent can only use an include subdomains policy
The server returns a NEL policy instructing the user agent
                                                                         to report DNS errors about requests to a subdomain, since the
to send NEL reports to a collector run by the attacker. They
                                                                         author of the policy has only been able to establish ownership
then update DNS to resolve bad.example to good.example’s
                                                                         of that portion of the domain name tree. Subdomain reports
IP address(es), and cause the user to make another request to
                                                                         about successful requests, and about any errors that occur
bad.example. Even though the request looks like it will go
                                                                         during or after connection establishment, are downgraded to
to the original bad.example server, it will instead be routed
                                                                         reports only containing information visible in DNS. Such re-
to good.example’s server; if there are any errors with the
                                                                         ports suffice for the service provider to discover unreachabil-
connection, NEL reports about those errors will be sent to
                                                                         ity due to DNS misconfiguration, e.g., the provider may have
the attacker’s collector. In this way, the attacker has been
                                                                         forgotten to add a DNS entry for a new subdomain.
able to collect error reports about good.example, even though
they do not own it. This kind of attack could also be used               3.4   What do clients upload?
to port scan an internal network, by repeatedly rebinding
                                                                         Report content. The most important part of a NEL re-
bad.example to several different internal IP addresses.
                                                                         port (Figure 3(b) shows an example) is the type, which
   NEL prevents such attacks by having user agents down-                 indicates whether the underlying request succeeded or
grade the quality of a report when the server IP address that            failed. If the request succeeded, the report’s type will
a user agent contacts is not one from which it previously re-            be ok; if it failed, it will describe what error condition
ceived the NEL policy header for this origin. In this case,              caused the request to fail. The full set of predefined er-
instead of reporting whether the request succeeded or not                ror types is given in the specification [11, §6]; exam-
(and the error type if not), the report simply states that the           ples include http.error, dns.name not resolved,
user agent’s DNS lookup yielded a different IP address. This             tcp.reset, and tcp.timed out. These predefined
information is safe to report to the attacker, since it is infor-        types are categorized hierarchically, so that one can find, for
mation that they already knew; and, because it relates to what           example, all TCP-related failures by looking for any type that
addresses bad.example resolves to, the attacker is actually              starts with tcp.
the legitimate party to deliver this information to. Note that              We have found it useful to collect NEL reports even for
this can limit the utility of NEL’s reports for domains that             successful requests, despite the fact that these requests also
resolve to many IP addresses (e.g., CDNs).                               show up in server-side logs. Reporting on successful re-
Subdomain reports. A consequence of activating NEL via                      3 Consider a PaaS cloud offering like Google App Engine, where inde-

headers in HTTP responses and enforcing SOP is that NEL                  pendent cloud applications are hosted at subdomains under appspot.com.

                                                                                        [{
  Report-To: {                                                                            "age": 60000, // The report was 1 minute old when uploaded
    "endpoints": // Try to send reports to one of these URLs                              "type": "network-error", // This is a NEL report
      [{"url": "https://collector1.com/upload-nel"},                                      "url": "https://example.com/about/", // The URL the client requested
       {"url": "https://collector2.com/upload-nel"}],                                     "user_agent": "Mozilla/5.0", // The client's User-Agent header
    "group": "nel", // The name of this group of endpoints                                "body": {
    "max_age": 300 // This set of collectors expires in 5 minutes                           "type": "tcp.timed_out" // The connection timed out
  }                                                                                         "phase": "connection", // The request failed during handshake
  NEL: {                                                                                    "server_ip": "203.0.113.75", // The client tried to connect to this IP
                                                                                            "sampling_fraction": 1.0, // This report had a 100% chance of collection
    "failure_fraction": 1, // Report all failed requests
                                                                                            "protocol": "h2", // The request was made using HTTP/2
    "success_fraction": 0.25, // Report 25% of successful requests                          "method": "GET",
    "include_subdomains": false, // Don’t report for subdomains                             "referrer": "https://example.com/", // The HTTP Referer
    "report_to": "nel", // Report to a collector in this group (above)                      "elapsed_time": 45000, // Lifetime of the request in milliseconds
    "max_age": 300 // This NEL policy expires in 5 minutes                                }
  }                                                                                     }]

                                  (a)                                                                                       (b)
                                                          Confidental and proprietary

Figure 3: Examples of (a) a service’s use of NEL headers in its HTTPS response to activate report collection by a user agent, and (b)
a report uploaded by a user agent. Comments are not included in real headers and reports.

quests lets us directly compare error ratios from successful                             even at the expense of hampering diagnosis. For example, if
and failed reports, without having to join the NEL logs with                             a user agent is using a client-configured proxy server, the IP
server-side logs. Comparing successful reports to web server                             address that the user agent attempts to connect to would be
logs also lets us estimate the relationship between NEL re-                              the IP address of that proxy server. Since that proxy config-
port volumes and actual request volumes.                                                 uration is not intended to be visible to the server, we cannot
   In addition to the type, NEL reports can only contain a                               include the IP address in the report. Note that this restric-
fixed set of additional information, as defined by the public                            tion only applies to proxies configured by the end user. If
specification. This helps ensure that implementors do not ac-                            their ISP is using a transparent proxy for all of its customers’
cidentally include additional information that would violate                             requests, any individual user agent won’t easily be able to
our desired privacy properties. In authoring the specifica-                              detect this. That means that the server IP reported by the
tion, our primary constraint when determining which fields                               user agent will still be the actual address of the origin server,
to include is to ensure that every field in the report contains                          while the client IP address seen by the server and any NEL
information that the server can already see during its normal                            collectors will be the address of the transparent proxy.
processing of the request.                                                                  Similarly, we cannot include the IP address of the DNS re-
   Given this constraint, NEL reports include basic infor-                               solver that the client uses. For DNS-related network outages,
mation about the request: URL (with user credentials and                                 this would be useful information to collect, since it would
fragment identifiers removed), HTTP request method (GET,                                 help the service owner determine whether a rogue or mis-
POST, etc.), application and transport protocol (HTTP/1.1,                               configured DNS resolver is at fault for an outage; however,
HTTP/2, QUIC, etc.), User-Agent string, and referrer. The                                since this information is not visible to the server when pro-
reports also include the HTTP status code of the response, if                            cessing a request, we cannot include it in a NEL report.
one was received, and how long the request took to complete.                                NEL reports also do not include details about HTTP re-
   Reports also contain the IP address of the server that the                            quests that are immaterial to diagnosing reachability prob-
user agent attempted to connect to. For most requests, this                              lems. For example, user agents exclude cookies and URL
is the public IP address of the service’s front-end server that                          parameters from reports. A NEL report does include the full
directly accepts incoming connections from end users. In-                                path that a request was issued for, not just the hostname to
clusion of this IP address in reports is crucial to enable de-                           which the request was issued. We have not found much use
tection of DNS hijacking; though the error type in the report                            for this information so far, but it may prove useful to an oper-
may indicate successful TCP connection setup, the server IP                              ator whose service configuration varies across different path-
address mentioned in the report will not be one used by any                              names under the same origin.
of a service’s front-end servers.                                                        Sampling rates. For high-volume sites, it is undesirable
   As mentioned above, there are several situations where a                              to have clients generate NEL reports about every attempted
NEL report is downgraded for privacy reasons; for instance,                              request, since that could double the number of requests a
when the server IP of the request is not one that the corre-                             client must make and would require the site’s collection in-
sponding NEL policy was received from. In these cases, any                               frastructure to be able to deal with the same full volume of
privacy-sensitive fields are modified or removed from the re-                            request traffic as the actual site. NEL allows service opera-
port, to maintain the property that the report only contains                             tors to define a sampling rate, instructing user agents to only
information that the policy author already had access to. The                            generate reports about a random subset of requests. More-
NEL specification [11] contains more detail about precisely                              over, they can provide separate sampling rates for successful
which fields are modified or removed, and when.                                          and failed requests. Typically, one will want to configure a
What do reports not contain? There are many details                                      very high sampling rate for failed requests, since those re-
about the client that we explicitly exclude from NEL reports,                            quests are more operationally relevant and more important

to collect as much information about as possible. The util-        of IP (if IPv4 is reachable, but not IPv6); different AS num-
ity of collecting reports for successful requests is largely to    ber (to account for BGP/routing issues); different transport
estimate their total number, so lower sampling rates (e.g., 1–     protocol (e.g., for QUIC-specific problems); and different
10%) are typically sufficient. Each NEL report includes the        hostname, registrar, and DNS server4 (if the service’s name-
sampling rate in effect when that particular report was gen-       server is unreachable). Later, in Section 4, we recount the
erated, which allows collectors to weight each report by the       kinds of collector diversity that have proved to be most valu-
inverse of its sampling rate when determining totals.              able in our experience.
   To reduce overhead, it may be tempting to adaptively vary          Given the effort necessary to ensure that collectors for a
the sampling rate over time. However, the need to increase         service do not share the same failure modes as the service it-
sampling rates will arise precisely when an outage occurs.         self, one may wonder whether the collectors could be used to
At that point, it will be infeasible for the service provider to   improve the availability of the service, beyond collecting ev-
update the NEL policy being used by affected clients.              idence of its (un)reachability. However, a NEL collector re-
   Google uses a 5% sampling rate for successes and 100%           quires significantly fewer resources than necessary to run the
for failures. We chose these numbers based on our expe-            monitored service. In particular, NEL collectors typically do
rience working with NEL: (1) we find a lower sampling              not need to make the same latency guarantees as interactive
rate dilutes our data too much when examining small user           web requests. Therefore, a service’s collection infrastructure
populations (e.g., when investigating outages in small ISPs),      is unlikely to have the necessary capacity for an operator to
and (2) we want a relatively consistent report traffic volume,     serve affected users from the collectors when these users are
rather than massive spikes in load during major outages.           unable to access the service normally.
3.5   Where do clients upload reports to?                          Load balancing and failover. NEL enables service opera-
                                                                   tors to define arbitrary load balancing and failover behavior
Once a user agent has generated reports about requests to          for their collectors. Inspired by the DNS SRV record [17],
an origin, those reports must somehow be sent back to the          a NEL policy can specify an optional weight and priority
service operator’s monitoring infrastructure. To do this, the      for each collector. When choosing which collector to up-
service operator defines a set of collectors, giving an upload     load a report to, a user agent will randomly select a collector
URL for each one (see Figure 3(a)). Since the set of collec-       from those with the smallest priority value, weighted by their
tors is defined in the NEL policy included in HTTP response        weight values. The user agent keeps track of whether up-
headers, service operators have full control over where NEL        loads to a particular collector fail too frequently; if so, that
reports about their origins are sent to.                           collector is marked as pending, and taken out of rotation.
   User agents will periodically batch together reports about      This ensures that collectors with higher priority are only at-
a particular origin, and upload those reports to one of the        tempted if all collectors with lower priority have failed. This
origin’s configured collectors. The report upload is a sim-        mechanism gives service operators maximum flexibility in
ple POST request, with the JSON-serialized batched report          determining how to configure their collection infrastructure.
content in the request payload.                                       If all of the collectors are unreachable, the user agent will
   Report uploads are subject to Cross-Origin Resource Shar-       retain the reports in memory for a small amount of time (typ-
ing (CORS) [32] checks. If the origin of the collector is dif-     ically 15 minutes). When this happens, it often indicates a
ferent than the origin of the requests that the NEL reports de-    complete loss of connectivity on the part of the user. Dur-
scribe, the user agent will perform a CORS preflight request       ing this time, the user agent will continue attempting to de-
to verify that the collector is willing to receive NEL reports     liver the reports (typically once per minute, with exponen-
about the origin. If the CORS preflight request fails, the NEL     tial backoffs). If the reports have still not been delivered
report will be silently discarded. Reports are only uploaded       after several attempts, they are dropped. The short interval
over HTTPS to prevent leaking their content to passive in-         ensures that we have visibility into temporary connectivity
network monitors.                                                  losses, while not requiring much storage in the user agent.
Collector failure modes. For an operator to detect out-               Note that a NEL user agent will also upload reports sum-
ages in a timely manner, it is crucial that clients be able to     marizing the success or failure of its attempts to upload a
upload NEL reports even when they are unable to reach the          NEL report to a collector; after all, attempts to upload NEL
monitored service. This requires that the collection path dif-     reports are also HTTP requests. We refer to these as meta re-
fer from the request path in as many ways as possible. As          ports. Such meta reports help a service provider detect prob-
a consequence, not only must the collectors be hosted dif-         lems that clients face in contacting its collectors. To prevent
ferently than the monitored service, but it is desirable that      infinite recursion, user agents generate meta reports only for
there be significant hosting diversity among those collectors.     uploads of NEL reports that are not meta reports.
Examples of the ways in which collectors might differ from
the monitored service include: different IP address (to learn          4 Note that all of these must be different for the client to use a completely

about the service’s IP being unreachable); different version       different set of nameservers to resolve the collector’s hostname.

 Feature            Domain Reliability     NEL W3C standard         • One consequence of NEL being opt-out is that its users
 Adoption model     Opt-in                 Opt-out                    will represent a more uniform sample of a service’s user-
 Activation time    Browser start          After first successful     base. Because of this, we expect to more confidently gen-
                                           request to an origin       eralize results from NEL to non-NEL clients.
 Activation         None                   HTTP response headers
                                                                    • With Domain Reliability, the list of origins for which
 overhead
                                                                      clients generate reachability reports and the list of collec-
 Coverage           Google origins         Any HTTPS origin
                                                                      tors to which they upload these reports was hard-coded
Table 3: Comparison of the two implementations of NEL:                into Chrome. Any updates to these lists were delivered
the version that monitors reachability from Chrome’s users to         as part of Chrome’s regular update process, resulting in a
Google’s services versus the W3C standard. The latter incurs          multiple-week lead time to push any monitoring changes
additional overhead to be generic.                                    to our users. In contrast, with NEL, any web service gets
Censorship resistance. Although we have found NEL use-                to bootstrap the origins to monitor and the collector do-
ful in detecting and investigating state-sponsored censorship,        mains by including this information as headers in the ser-
NEL itself is not particularly resistant to censorship. An at-        vice’s HTTP responses. This allows monitoring changes
tacker who can block access to an origin can also trivially           to be picked up immediately, with the cost of increased
enumerate all NEL collectors for the origin, and block access         overhead in client-server traffic.
to those collectors. Service operators could try to introduce a     • An implication of the previous point is that NEL can en-
modicum of censorship resistance by hosting NEL collectors            able a client to upload reachability reports for a particu-
in cloud providers, thereby tying the fate of report collection       lar origin only after that client has successfully commu-
to the cloud provider as a whole. An operator could also              nicated with that origin at least once. Without doing so,
make it harder for an adversary to identify all of its collec-        the client would neither know that it must generate and
tors by returning different subsets of collectors to different        upload reports for this origin, nor know which collectors
clients [34]; however, a NEL collector may be discernable             to upload these reports to. Because its configuration was
via network traffic analysis [14].                                    hard-coded in Chrome, Domain Reliability enabled mon-
Report authenticity. Since NEL reports are generated by               itoring of a client’s reachability to Google’s services even
user agents running on untrusted client devices, there is noth-       if that client had never successfully been able to commu-
ing preventing clients from generating and uploading fraud-           nicate with any Google origin.
ulent reports. A service provider can account for this chal-        • Since Domain Reliability was only implemented in
lenge by only reacting to problems that affect a large enough         Chrome, it could not reveal reachability issues faced by
population of unique client IP addresses (typically dozens).          users of other browsers. With NEL, a service can collect
This measure ensures that a malicious entity can only cause a         reports from any HTTP client that implements the pro-
service operator to react to fake outages if they control a large     posed W3C standard [11].
number of client devices (e.g., a botnet operator). However,        • Because Domain Reliability’s configuration was encoded
making NEL robust to fraud in this manner comes with the              in source code, we relied on the existing code review pro-
risk of minimizing the impact of an outage which affects a            cess to ensure that the configuration adhered to our desired
few IP addresses shared by many client devices, e.g., when            security and privacy properties. Because this configura-
many devices are behind a shared NAT.                                 tion was restricted (by policy) to Google properties, we
                                                                      did not have to downgrade Domain Reliability reports like
3.6   Domain Reliability
                                                                      is needed for NEL in some situations; instead, we ensured
Thus far, this section has described the public standard [11]         that Domain Reliability’s hard-coded policy prevented re-
which is usable by all services and browsers, and available           ports from being sent at all in those situations.
in Chrome as of version 69. We also implemented these
ideas in an earlier proof-of-concept called Domain Relia-           4   Deployment Experiences
bility, which could only monitor reachability from Chrome           This section relays some of our experiences with the tech-
users to Google services. There are some important differ-          niques described in the previous section. In each case, data
ences between Domain Reliability and NEL (see Table 3).             alerted us to the presence of a problem and hinted at a
• Since Domain Reliability was not generally available to all       cause based on the population of users reporting that prob-
  service operators and only monitored Google properties,           lem (i.e., the “shape” of the problem); however, these tech-
  it required users to explicitly opt in to report collection.      niques are most useful in concert with other network diag-
  With NEL, any user agent which implements the standard            nostic tools that can dig deeper into specific problems and
  collects reports by default for origins which include NEL         provide “smoking gun” evidence of a particular cause.
  policies in their responses. A user can opt out of NEL               Note that this section deals with Domain Reliability, the
  either globally or on a per-origin basis.                         initial prototype of these concepts that we developed to mon-

 $ traceroute X.Y.Z.33
                                      Loss%   Snt    Last     Avg    Best    Wrst StDev
   1.|--   ip1.isp.net                 0.0%   100     0.2     1.1     0.2    49.3   5.5
   2.|--   ip5.isp.net                 0.0%   100     6.1     8.3     4.5    12.4   2.3
   3.|--   ip6.isp.net                 0.0%   100     8.4     8.8     7.5    36.5   3.9
   4.|--   ip7.isp.net                 0.0%   100     7.6     9.2     7.6    18.2   2.8
                                                                                                     $ traceroute X.Y.Z.32
   5.|--   ip8.isp.net                99.0%   100   2671.   2671.   2671.   2671.   0.0                                                            Loss%       Snt       Last    Avg     Best      Wrst StDev
   6.|--   ???                        100.0   100     0.0     0.0     0.0     0.0   0.0               1.|--   ip1.isp.net                           0.0%        10        0.2    0.2      0.2       0.3   0.0
   7.|--   ???                        100.0   100     0.0     0.0     0.0     0.0   0.0               2.|--   ip2.isp.net                           0.0%        10        6.9    8.4      4.8      11.8   2.4
   8.|--   ip9.isp.net                99.0%   100   7314.   7314.   7314.   7314.   0.0               3.|--   ip3.isp.net                           0.0%        10        7.7    8.3      7.5      10.7   1.1
   9.|--   ???                        100.0   100     0.0     0.0     0.0     0.0   0.0               4.|--   ip4.isp.net                           0.0%        10       33.5   10.7      7.5      33.5   8.1
  10.|--   ???                        100.0   100     0.0     0.0     0.0     0.0   0.0
                                                                                                      5.|--   ip1.google.com                        0.0%        10       49.7   49.2     43.3      55.2   4.4
  11.|--   ip10.isp.net               99.0%   100   5179.   5179.   5179.   5179.   0.0
  12.|--   ???                        100.0   100     0.0     0.0     0.0     0.0   0.0               6.|--   ip2.google.com                        0.0%        10       49.0   48.5     44.3      51.6   2.6
  13.|--   ip11.isp.net               99.0%   100   2722.   2722.   2722.   2722.   0.0               7.|--   ip3.google.com                        0.0%        10       47.6   47.8     44.3      53.2   2.9
  14.|--   ???                        100.0   100     0.0     0.0     0.0     0.0   0.0               8.|--   X.Y.Z.32                              0.0%        10       48.9   49.8     45.9      58.7   4.6

                                (a)                                                                                                                    (b)
                                                                       Confidental and proprietary

Figure 4: (a) Traceroute to the affected IP address appears to show a routing loop in the last-mile ISP, and (b) traceroute from the
same vantage point to an adjacent IP address exits the ISP within a few hops. Hostnames and IP addresses are anonymized.
                                                                                                                                                                                                          Confidental and proprietary

itor traffic only to Google’s services. We have monitored                                                                                          216.58.192.0/22
                                                                                                                                                       LEAKED
                                                                                                                                                                                216.58.192.0/22

Google’s services with it since Chrome 38 in 2014 and are                                                         Trans
                                                                                                                 Telecom
                                                                                                                                          China
                                                                                                                                         Telecom
                                                                                                                                                                     MainONE                       Google
                                                                                                                                                                     AS 37282                     AS 15169
currently migrating our monitoring to use NEL. Although                                                          AS 20485                AS 4809


Domain Reliability and NEL are not qualitatively different,
Section 3.6 explains how one might expect our experiences                                                                                                                                    216.58.192.0/19


to differ once we fully migrate to NEL.
                                                                                                                                      Verizon
                                                                                                            Charter
4.1   Unreachability of a single IP address
                                                                                                                                     Wireless
                                                                                                            (Many                    AS 22394
                                                                                                            ASNs)
                                                                                                                                                      (Several                          Legit advertisements
In December of 2018, Chrome clients started reporting fail-                                                                 Cogent
                                                                                                                                                       (Several
                                                                                                                                                        (Several
                                                                                                                                                        other
                                                                                                                                                         other
                                                                                                                                                          other
                                                                                                                                                     networks)                          Leaked advertisements
                                                                                                                                                      networks)
ures of TCP connections and QUIC sessions made to a single                                                                  AS 174                     networks)                        Client traffic


Google IP address. The problem affected all requests to that                                                                                                                                         Confidental and proprietary


IP from all users in every ISP in one country for the follow-                                         Figure 5: AS 37252 leaked prefixes to its peers, which ultimately
ing two weeks.                                                                                        misrouted traffic in several downstream ASNs. NEL quantified
   Further manual investigation revealed that traceroutes                                             the impact of the leak on users in those downstream networks.
from an affected host to that IP were failing inside a transit                                        even more difficult to feel confident that the problem had
ISP which dominates wired connectivity within that coun-                                              been completely resolved.
try. We also occasionally noticed IPs belonging to this transit                                          However, NEL alone was not enough to diagnose this is-
provider in high-TTL hops of the traceroute, suggesting that                                          sue because it gave no information about the location of the
packets were stuck in a routing loop in that ISP’s network                                            problem other than the set of users affected. We needed other
(see Figure 4). The problem was eventually resolved after                                             tools, like traceroute, to identify which network links were
we contacted the ISP, although we never learned how they                                              impacted and that most, if not all, of the Internet traffic in
presumably fixed it.                                                                                  that country transits through one ISP.
   NEL was useful in this case in several ways.
                                                                                                      4.2      BGP leakage
• It let us quickly detect a problem we may have never no-
  ticed otherwise. The impacted IP served content that is                                             On November 12, 2018, AS 37282 leaked its routing table
  visible to users but is not critical (e.g., thumbnail images),                                      to its upstream providers. As shown in Figure 5, this leak
  which may be why we received no reports about this prob-                                            rerouted traffic destined for some Google prefixes, causing
  lem on social media, and why there was no visibility on                                             packet loss for many of our users. The network operations
  crowdsourced sites like downdetector.com.                                                           community noticed this incident and the media widely re-
• NEL was additionally helpful in confirming that the prob-                                           ported on it.5
  lem had gone away, particularly since the ISP never noti-                                              NEL saw this incident as an increase in connection time-
  fied us that they fixed it.                                                                         outs for the leaked prefixes. Although many other monitor-
                                                                                                      ing tools had clear visibility of the leaked BGP routes [7],
• Diversity of our NEL collectors was trivially useful in this
                                                                                                      NEL directly told us the incident’s impact on user traffic.
  case; a collector hosted on any IP other than the one im-
                                                                                                      In some networks, NEL reported that nearly all requests to
  pacted could have successfully received report uploads.
                                                                                                      these prefixes timed out. Moreover, diversity of our NEL
   Although other network monitoring tools could have                                                 collectors was useful in this case, because we had collectors
caught this problem (e.g., active probing of all serving IPs),                                        running in IP prefixes not affected by the leakage.
it would have been difficult to assess the scale of users im-
pacted or even to achieve dense enough probe coverage to                                                5 https://www.manrs.org/2018/11/route-leak-causes-major-

know how many ISPs were affected. It would have been                                                  google-outage/

   On the other hand, NEL said nothing about the cause of            only clients using QUIC [23] were affected. This was cor-
the outage other than perhaps that the problem was local-            roborated by reports from users.6
ized to a specific set of prefixes. It would probably be most           Our operations team traced the problem back to a bad
valuable to overlay NEL data on existing BGP leak detection          server configuration change, and mitigated it soon after. The
tools, to distinguish relatively benign incidents of BGP leak-       problem caused machines in the affected datacenters to drop
age (i.e., that do not impact much traffic) from major events        all traffic on established QUIC sessions. Although QUIC
like this one.                                                       clients transparently fall back to TCP when QUIC cannot es-
   Note that BGP leaks that have no impact on the users of           tablish a connection, that did not help in this case because
Google’s services are likely since Google advertises and uses        we only dropped packets after a connection was established.
different IP prefixes to serve its users in different parts of the      This situation illustrates the value of black box traf-
world. Hence, when an ISP erroneously advertises one of              fic monitoring; if operations teams only monitor specific
our prefixes, this has no impact on users if this ISP operates       protocol-level metrics (e.g., number of connections estab-
in a region far from where we use the affected prefix. NEL           lished), then there is a chance that those metrics do not tell
helps us avoid troubleshooting such inconsequential prob-            the whole story. NEL lets operations teams know whether
lems, whose impact would otherwise have been hard to de-             users’ connections are healthy end-to-end.
termine only based on analysis of BGP data.                             NEL collector diversity was useful in this case because
                                                                     the problem was localized to a few datacenters; clients could
4.3   Malware-induced DNS hijacking                                  successfully upload NEL reports to other locations.
                                                                     4.5 Monitoring of NEL report uploads
In February of 2018, NEL reported that users in a large ISP
were resolving several of our domains to non-authoritative IP        In addition to discovering network outages, we have also
addresses belonging to a third-party cloud hosting provider.         leveraged NEL’s collection infrastructure to monitor previ-
Clients could still complete requests to these domains (i.e.,        ously unmonitored infrastructure. Other operators of NEL
most reports we received had type ok), suggesting the pres-          collectors may do the same.
ence of a layer 3 proxy server. Although requests were suc-             Domain Reliability monitors only Google’s first-party ser-
cessful, this was still concerning because a proxy could re-         vices, but not customer-owned origins hosted on Google’s
duce performance and reliability. We could not find reports          cloud infrastructure. This is currently a blind spot in our
of the problem online or reproduce the issue ourselves from          monitoring. Moreover, NEL will not allow us to monitor
our CDN infrastructure in the ISP.                                   customer-owned origins directly, since NEL’s privacy design
   We later discovered a rogue DNS resolver associated with          gives the customer, and not their cloud provider, control over
malware that was responding to DNS requests in much the              whether reports are collected and where they are sent.
same way. We theorize that either (1) an ISP DNS server                 To help ameliorate this limitation, in addition to our ex-
had been compromised to resolve requests using the rogue             isting diverse set of NEL collectors, we run another set of
resolver, or (2) many machines and/or home routers in that           collectors hosted on our cloud infrastructure. As a result,
ISP had been similarly compromised.                                  whenever a user makes a request to a Google service, the
                                                                     user agent generates a NEL report and attempts to upload it
   This case highlights a key advantage of NEL over tradi-           to one of our cloud collectors with a probability based on the
tional active probing: NEL monitors actual user network              values of the weight fields in our NEL policy. The user agent
conditions and configurations, which can differ from those           then generates and uploads a meta report about the upload of
of dedicated monitoring infrastructure. It can detect massive        the original report.
problems that are simply invisible to other forms of moni-              Although this technique does not grant us visibility into
toring. However, this case also highlights that NEL is not           problems affecting individual cloud tenants (e.g., a miscon-
necessarily very helpful in debugging problems; in this case,        figured tenant firewall), it at least lets us detect problems af-
since NEL does not report which DNS resolver clients use,            fecting our entire cloud infrastructure, even if those problems
it did not help us make progress on the problem.                     are localized to a small number of clients. For example, this
  Note that collector diversity was unnecessary in this case         helped us quickly confirm that the BGP leak in Section 4.2
because requests to these hijacked domains still worked.             also impacted our cloud infrastructure.
Nonetheless, NEL was helpful because it alerted us to the               One caveat to meta reports is that they are not represen-
presence of a proxy server associated with malware.                  tative. Any sampling rates defined in the NEL policy are
                                                                     compounded for meta reports, making it more difficult to get
4.4   Protocol-specific problems                                     a large enough collection of meta reports to derive a statisti-
                                                                     cally meaningful signal. Clients with unreliable connectivity
On March, 17, 2017, NEL observed that users were having
                                                                     are more likely to attempt to send NEL reports, and to fail
trouble connecting to Google services in two of our datacen-
ters in the United States and Europe. On closer inspection,            6 https://news.ycombinator.com/item?id=13892431

doing so. So, we see higher baseline error rates for NEL            clients are 532 ± 34 bytes long; clients batch these into up-
report traffic from such clients compared to the global set of      loads that contain an average of 1.3 reports each. Clients
NEL reports. As a result, we cannot compare NEL error rates         upload a batch of reports about an origin once per minute.
for our cloud infrastructure and our non-cloud infrastructure;         Clients pay additional bandwidth overhead for failed up-
but, trend analysis on meta reports remains useful.                 loads: 1) Clients incur connection establishment overhead
                                                                    multiple times as they retry an upload to different collectors,
5     Deployment Challenges
                                                                    and 2) each failed upload may itself generate a NEL report.
This section discusses several practical challenges we en-             Service operators can control these overheads with sam-
countered when deploying NEL. Other web service opera-              pling rates in the NEL header. In particular, because most
tors are likely to encounter similar hurdles.                       requests succeed, the success fraction field can have a large
5.1   Collector diversity                                           impact on total upload traffic. For example, over 90% of
                                                                    requests to our services succeed and reports about those re-
As seen in some of our case studies (§4), diversity in the          quests do not contribute much to our ability to reason about
deployment of collectors has been crucial to collect client         network outages other than by establishing proper baselines.
unreachability reports in a timely manner. For example, in          We set success fraction to 0.05, but success reports are still
the BGP leak case, it was crucial that we had a collector in a      almost 40% of our upload traffic.
different prefix from those leaked.
   While such diversity existed in Google’s infrastructure          5.3   Provisioning for bursty workloads
even prior to our deployment of NEL, hosting collectors
                                                                    We could further reduce success fraction, but at a cost. Al-
across the globe, in multiple prefixes and AS numbers, and
                                                                    though request failures are much rarer than successes, fail-
supporting multiple IP versions is unlikely to be straight-
                                                                    ures are very bursty. Major network outages can cause large
forward for an arbitrary web service. Therefore, to ease
                                                                    networks to send tens or hundreds of times more NEL re-
the use of NEL by other web services, we envision public
                                                                    ports than they normally would. A service’s NEL collection
cloud providers offering “NEL collectors as a service.” Like
                                                                    infrastructure must be provisioned to handle these cases or
Google, other large cloud providers also have a rich diversity
                                                                    risk data collection failing at exactly when it is most needed.
of global infrastructure that naturally lends itself for use as
NEL collectors.                                                        NEL client retry logic compounds this by causing clients
                                                                    to retry uploads to collectors when they are overloaded. We
5.2   Overhead                                                      currently mitigate this by having our collectors always re-
NEL increases network traffic for both clients and service          turn HTTP 200, which prevents clients from retrying uploads
providers in two ways: 1) the additional header that the ser-       when the collection infrastructure is overloaded. If more ex-
vice provider must include in its responses to clients’ HTTP        plicit control is needed, the NEL specification requires user
requests, and 2) reports that clients upload to NEL collectors.     agents to stop sending reports to a collector entirely when
Response header overhead. As shown in Figure 3, servers             that collector returns an HTTP 410 (Gone) response.
must send two headers to activate NEL: NEL and Report-To.           5.4   Application-layer retries
Although exact sizes vary depending on the number of col-
lectors and the presence of non-default options, headers are        It can be tempting to compare error rates across different
typically several hundred bytes long and are uncompressed           kinds of applications, domains, and URLs. For example, one
unless the client is using HTTP/2. Furthermore, there is cur-       might suspect that if one domain has four times the error rate
rently no way for clients to tell the server whether they sup-      of another then something must surely be wrong with the for-
port NEL or already have activated NEL for an origin, so            mer domain. Although this might be true, application-layer
servers typically include headers on all requests to all clients.   retry logic could also explain the discrepancy.
This could be particularly problematic when serving many               For example, if a Web application makes a lot of AJAX
small objects, in which case NEL headers could constitute a         requests to example.com and retries those requests when
significant fraction of the total response size.                    they fail, then the overall NEL error rate for example.com
   Service operators have several ways to curtail NEL’s             will appear higher. This is because successive request fail-
bandwidth usage. Operators could (1) only serve NEL on              ures are likely not independent; if a request fails once, it is
a fixed fraction of responses, (2) try to predict which clients     much more likely that a second request will also fail.
support NEL based on their User-Agent header, or (3) only              This logic also applies to user-initiated retries. If a par-
serve NEL headers on HTTP/2 connections, under the as-              ticular request is more likely to elicit a retry (e.g., a browser
sumption that (due to NEL’s relatively young age) all clients       reload) from a user when it fails, that can also inflate the NEL
that support NEL also support HTTP/2.                               error rate. For example, a user may be more likely to retry
Report upload overhead. NEL also incurs overhead when-              requests that are very important to them whereas they may
ever clients upload reports. Reports we receive from our            simply abandon more trivial requests.

6   Future Work                                                    mance distributions, characterizing middleboxes, measuring
                                                                   network topologies, etc. Since none of this data needs to be
End-to-end report encryption.           As mentioned in Sec-       compiled in a timely manner, uploading via redundant paths
tion 5.1, one easy way operators can increase the likelihood       has been unnecessary in these efforts, unlike in NEL. More-
that clients can successfully upload NEL reports is to host        over, since the measurements gathered in these systems do
collectors in cloud providers. However, NEL clients cur-           not contain application traffic, protecting user privacy has
rently assume that operators trust collectors and therefore do     not been a concern.
not encrypt reports beyond uploading them using HTTPS.
                                                                      Windows Error Reporting (WER) [15] is most similar in
If an operator does not trust a cloud, their only option cur-
                                                                   spirit to NEL in that it too uploads error reports gathered
rently is to use the cloud as a layer 3 proxy and terminate
                                                                   at the client. WER does have to pay attention to privacy
HTTPS elsewhere. Future versions of NEL could encrypt
                                                                   by pruning crash reports before uploading them. However,
reports end-to-end (e.g., using PGP), which would decouple
                                                                   since uploaded crash reports are analyzed at a later point in
collectors (which would see reports as opaque blobs) and re-
                                                                   time [18], failover on the upload path was unnecessary in this
port analyzers (which could decrypt reports).
                                                                   case too.
Automated triage. Individual NEL reports are rarely use-              Odin [10] enables Microsoft to gather measurements from
ful; we derive utility from examining collections of reports       their clients to their CDN. By incorporating active measure-
and identifying patterns in those collections. For example, if     ment logic into client applications, Odin preempts concerns
we see many timeouts of requests to many IPs in a prefix, that     regarding coverage associated with dedicated monitoring in-
may indicate a problem with that entire prefix. We currently       frastructure. Like NEL, Odin too attempts to make report
look for problems in a manually curated set of dimensions          uploading fault-tolerant via proxies in third-party networks.
based on our past experience, but in the future could try to       Unlike NEL, since Odin only relies on measurements that it
automatically identify problematic user populations without        actively issues, purging reports to protect privacy is not a sig-
a priori knowledge of likely problems. Based on the “shape”        nificant concern. Odin also cannot be used by services not
of a given problem (i.e., the distribution of different types of   managed by Microsoft.
NEL reports), we could attempt to automate triage of the
problem. For example, if we detect that all users in just one      8   Conclusion
ISP are having difficulty accessing a domain, then we could
                                                                   Despite the wide range of solutions available today to de-
automatically notify that ISP, since their network configura-
                                                                   tect and diagnose reachability issues over the Internet, ser-
tion is a likely culprit.
                                                                   vice operators lack an important capability: the ability to
Reducing overhead. Future versions of NEL might add                quantify the number of clients affected by any particular out-
several mechanisms to reduce the overhead of NEL policy            age. To fill this void, we presented NEL, which equips ser-
headers. For example, we might let services specify NEL            vice providers with timely collection of reachability reports
policies in external URLs, using a mechanism like the pro-         generated at the client. Incorporation of NEL’s techniques
posed Origin Policy [33] or Site-Wide HTTP Headers [26]            into Chrome has proved invaluable over the last few years in
standards. By making their NEL policy object cacheable,            monitoring reachability to Google’s domains. Motivated by
service providers can preclude clients from having to fetch        our experience, we have proposed NEL as a W3C standard
the policy from the external URL after every successful re-        to spur support for it in other user agents and to enable other
quest. We may also let clients include request headers which       service providers to benefit from this capability.
indicate when the server should send NEL policy headers,
using a mechanism similar to HTTP Client Hints [16]. This          Acknowledgements
would prevent servers from needlessly sending NEL headers          We thank the anonymous reviewers and our shepherd, Ky-
to clients that will ignore them.                                  oungSoo Park, for their valuable feedback. Many people at
7   Related Work                                                   Google have contributed to this project, particularly through
                                                                   their experiences investigating problems NEL has detected.
Earlier in Section 2, we reviewed prior work which shares          In particular, we thank Emma Christie, Fred Douglas, Lo-
NEL’s aim of detecting and diagnosing service unreachabil-         gan Ingalls, Martijn Stevenson, Matthew Steele, Steve Wang,
ity. Here, we compare NEL to other systems which also rely         Wesley Darlington, and Yan Avlasov for investigating issues
on client-side measurements.                                       that NEL has detected over the years. Debashish Chatterjee,
   There have been a number of previous client-side mea-           Francesco Marabotto, Jelmer Vernooij, and Mitchell Jeffrey
surement systems focused on one of the following goals:            have provided valuable support from Google’s SRE organi-
continual collection of passive measurements [30], enabling        zation. We thank Chris Bentzel for initial sponsorship of
users to measure their network [21], or orchestration of mea-      the project. Harsha Madhyastha’s participation was funded
surement campaigns [29, 25, 13]. All of these efforts aim          in part by the National Science Foundation via award CNS-
to gather measurements with the aim of compiling perfor-           1563849.

References                                                               specifying the location of services (DNS SRV). Tech-
 [1] BGP errors are to blame for Monday’s Twitter out-                   nical report, IETF, 2000.
     age, not DDoS attacks.           https://www.csoonline.      [18]   S. Han, Y. Dang, S. Ge, D. Zhang, and T. Xie. Per-
     com/article/3138934/security/bgp-errors-are-to-                     formance debugging in the large via mining millions of
     blame-for-monday-s-twitter-outage-not-ddos-                         stack traces. In International Conference on Software
     attacks.html.                                                       Engineering (ICSE), 2012.
 [2] A DNS hijacking wave is targeting companies at an            [19]   X. Hu and Z. M. Mao. Accurate real-time identification
     almost unprecedented scale.          https://arstechnica.           of IP prefix hijacking. In IEEE Symposium on Security
     com/information-technology/2019/01/a-dns-                           and Privacy, 2007.
     hijacking-wave-is-targeting-companies-at-an-                 [20]   E. Katz-Bassett, H. V. Madhyastha, J. P. John, A. Krish-
     almost-unprecedented-scale/.                                        namurthy, D. Wetherall, and T. E. Anderson. Studying
 [3] Dynatrace. http://www.dynatrace.com.                                black holes in the Internet with Hubble. In USENIX
 [4] ELK stack: Elasticsearch, Logstash, Kibana. https:                  Symposium on Networked Systems Design and Imple-
     //www.elastic.co/elk-stack.                                         mentation (NSDI), 2008.
 [5] Google Stackdriver.          https://cloud.google.com/       [21]   C. Kreibich, N. Weaver, B. Nechaev, and V. Paxson.
     stackdriver/.                                                       Netalyzr: Illuminating the edge network. In ACM In-
 [6] RIPE Atlas. https://atlas.ripe.net.                                 ternet Measurement Conference (IMC), 2010.
 [7] ThousandEyes.        https://www.thousandeyes.com/           [22]   M. Lad, D. Massey, D. Pei, Y. Wu, B. Zhang, and
     solutions/bgp-and-route-monitoring.                                 L. Zhang. PHAS: A prefix hijack alert system. In
 [8] A. Barth. RFC 6454: The Web Origin Concept. Inter-                  USENIX Security symposium, 2006.
     net Engineering Task Force (IETF), Dec. 2015.                [23]   A. Langley, A. Riddoch, A. Wilk, A. Vicente, C. Kra-
 [9] P. Anastas, W. R. Breen, Y. Cheng, A. Lieberman, and                sic, D. Zhang, F. Yang, F. Kouranov, I. Swett, J. Iyen-
     I. Mouline. Methods and apparatus for real user moni-               gar, and J. Bailey. The QUIC transport protocol: De-
     toring, 2010. US Patent 7,765,295.                                  sign and Internet-scale deployment. In ACM SIG-
[10] M. Calder, R. Gao, M. Schröder, R. Stewart, J. Pad-                COMM, 2017.
     hye, R. Mahajan, G. Ananthanarayanan, and E. Katz-           [24]   R. Mahajan, D. Wetherall, and T. Anderson. Under-
     Bassett. Odin: Microsoft’s scalable fault-tolerant CDN              standing BGP misconfiguration. In ACM SIGCOMM,
     measurement system. In USENIX Symposium on Net-                     2002.
     worked Systems Design and Implementation (NSDI),             [25]   A. Nikravesh, H. Yao, S. Xu, D. Choffnes, and Z. M.
     2018.                                                               Mao. Mobilyzer: An open platform for controllable
[11] D. Creager, I. Grigorik, A. Reitbauer, J. Tuttle, A. Jain,          mobile network measurements. In MobiSys, 2015.
     and J. Mann. Network Error Logging. W3C Editor’s             [26]   M. Nottingham. Site-Wide HTTP Headers. Internet-
     Draft, W3C Web Performance Working Group, 2019.                     Draft, IETF Network Working Group, 2017. https://
[12] A. Dainotti, C. Squarcella, E. Aben, K. C. Claffy,                  mnot.github.io/I-D/site-wide-headers/.
     M. Chiesa, M. Russo, and A. Pescapé. Analysis of            [27]   C. Reis, S. D. Gribble, T. Kohno, and N. C. Weaver.
     country-wide internet outages caused by censorship. In              Detecting in-flight page changes with web tripwires.
     ACM Internet Measurement Conference (IMC), 2011.                    In USENIX Symposium on Networked Systems Design
[13] M. Dhawan, J. Samuel, R. Teixeira, C. Kreibich,                     and Implementation (NSDI), 2008.
     M. Allman, N. Weaver, and V. Paxson. Fathom:                 [28]   P. Richter, R. Padmanabhan, N. Spring, A. Berger, and
     A browser-based network measurement platform. In                    D. Clark. Advancing the art of Internet edge outage
     ACM Internet Measurement Conference (IMC), 2012.                    detection. In ACM Internet Measurement Conference
[14] R. Ensafi, D. Fifield, P. Winter, N. Feamster, N. Weaver,           (IMC), 2018.
     and V. Paxson. Examining how the great firewall dis-         [29]   M. A. Sánchez, J. S. Otto, Z. S. Bischof, D. R.
     covers hidden circumvention servers. In ACM Internet                Choffnes, F. E. Bustamante, B. Krishnamurthy, and
     Measurement Conference (IMC), 2015.                                 W. Willinger. Dasu: Pushing experiments to the Inter-
[15] K. Glerum, K. Kinshumann, S. Greenberg, G. Aul,                     nets edge. In USENIX Symposium on Networked Sys-
     V. Orgovan, G. Nichols, D. Grant, G. Loihle, and                    tems Design and Implementation (NSDI), 2013.
     G. Hunt. Debugging in the (very) large: Ten years of         [30]   S. Sundaresan, S. Burnett, N. Feamster, and W. De Do-
     implementation and experience. In ACM Symposium                     nato. BISmark: A testbed for deploying measurements
     on Operating Systems Principles (SOSP), 2009.                       and applications in broadband access networks. In
[16] I. Grigorik and Y. Weiss. HTTP Client Hints. Internet-              USENIX ATC, 2014.
     Draft, HTTP Working Group, 2019. https://httpwg.             [31]   The Apache Software Foundation. Apache log files.
     org/http-extensions/client-hints.html.                              https://httpd.apache.org/docs/2.4/logs.html.
[17] A. Gulbrandsen, P. Vixie, and L. Esibov. A DNS RR for        [32]   A. van Kesteren. Cross-origin resource sharing. Tech-

     nical report, W3C, 2014.                                       tional Symposium on Stabilization, Safety, and Security
[33] M. West. Origin Policy. Draft Community Group Re-              of Distributed Systems, 2017.
     port, Web Incubator Community Group, May 2017.            [35] Z. Zhang, Y. Zhang, Y. C. Hu, Z. M. Mao, and
     https://wicg.github.io/origin-policy/.                         R. Bush. iSPY: Detecting IP prefix hijacking on
[34] M. Zamani, J. Saia, and J. R. Crandall. TorBricks:             my own. IEEE/ACM Transactions on Networking,
     Blocking-resistant Tor bridge distribution. In Interna-        18(6):1815–1828, 2010.

